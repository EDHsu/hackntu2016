Lab 2
========================================================
author: 
date: 
autosize: true

First Slide
========================================================

For more details on authoring R presentations please visit <https://support.rstudio.com/hc/en-us/articles/200486468>.

- Bullet 1
- Bullet 2
- Bullet 3




========================================================

LAB 2: Methodological beginnings - Density, Reciprocity, Triads, 
Transitivity, and heterogeneity. Node and network statistics.



========================================================
Lab 2 

The purpose of this lab is to acquire basic cohesion metrics of density, reciprocity, reach, path distance, and transitivity. In addition, we'll develop triadic analyses and a measure of ego-network heterogenity. 

本實驗的目的是獲得密度，互易性，到達，路徑距離和傳遞性的基本內聚度量。 此外，我們將開發三元分析和自我 - 網絡異質性的度量。

```{r, echo=FALSE}
# pre-load data, as same as lab 1
```

```{r, echo=FALSE}
#install.packages("NetData")
```

```{r, echo=FALSE}
library(igraph)
library(NetData)
data(kracknets, package = "NetData")
```

```{r, echo=FALSE}
# Reduce to non-zero edges and build a graph object
krack_full_nonzero_edges <- subset(krack_full_data_frame, 
                                   (advice_tie > 0 | friendship_tie > 0 | reports_to_tie > 0))
```

```{r, echo=FALSE}
krack_full <- graph.data.frame(krack_full_nonzero_edges) 
```

```{r, echo=FALSE}
attributes = cbind(1:length(attributes[,1]), attributes)
  
krack_full <- graph.data.frame(d = krack_full_nonzero_edges, vertices = attributes) 
```

```{r, echo=FALSE}
# advice_tie
krack_advice <- delete.edges(krack_full, 
                             E(krack_full)[get.edge.attribute(krack_full,name = "advice_tie")==0])
```

```{r, echo=FALSE}
# friendship_tie
krack_friendship <- delete.edges(krack_full, 
                                 E(krack_full)[get.edge.attribute(krack_full,name = "friendship_tie")==0])
```

```{r, echo=FALSE}
# reports_to_tie
krack_reports_to <- delete.edges(krack_full, 
                                 E(krack_full)[get.edge.attribute(krack_full,name = "reports_to_tie")==0])
```



資料取得 (Data Collection)
========================================================

由於人際網路的資料可能相當龐大及複雜，為了可以快速取得相關的資料及數據進行分析，我們可以根據問題選定目標族群，採用滾雪球取樣 (Snowball Sampling)

滾雪球取樣法是一種 "非隨機式抽樣" 的方法，透過人際關係網路，類似滾雪球般從一個人 (端點) 找到下一個人 (端點) ，逐漸累積到足夠的調查樣本為止稱之，這種抽樣方式常用於社會學研究

滾雪球抽樣法的優點在於可快速收集到少數人際關係樣本，此方法使用得當不但費用少且簡單有效，但滾雪球抽樣法的缺點也是 "非隨機式抽樣"，在某特定的人際網路中，抽取的樣本可能具有極高的同質性

<http://terms.naer.edu.tw/detail/1678729/>



滾雪球取樣 (Snowball Sampling)
========================================================

通常在進行 Snowball Sampling 時，我們會先選定位於人際關係網路中重要的點，再以此去擴散抽樣的範圍．並不會無限制的一直抽樣下去，大概會限縮於三層的關係 (朋友、朋友的朋友、朋友的朋友的朋友)

影片: <https://www.youtube.com/watch?v=BIEteh4nryM>



Node-Level Statistics
========================================================

根據前面 Snowball Sampling 的描述，我們該如何找尋重要的點呢?

重要的點包含四種:
- 人際網路的明星
- 人際網路最有效的訊息傳遞者
- 人際網路中不同群體的樞紐
- 人際網路中幕後決策的藏鏡人



用 krack_friendship 來操作看看吧
========================================================

接下來我們聚焦在 friendship 這個網路，透過一些指標找尋這些重要的點

```{r, echo=FALSE}
krack_friendship <- delete.edges(krack_full, 
                                 E(krack_full)[get.edge.attribute(krack_full,name = "friendship_tie")==0])
```

```{r, echo=FALSE}
plot(krack_friendship)
```



度數 (degree)
========================================================

度數 (degree) 指的是某端點 (vertex) 與其他端點的連接線的數目，其中又因連接線的方向分為兩種
- in-degree : 連入的數目
- out-defree : 連出的數目

以 friendship 來說，代表友誼的關係並不是雙向的 (天啊~好像有點殘忍~囧)



來思考一下 in-degree 的意義
========================================================

套用前面的 krack_friendship 觀察看看，in-degree 越高，代表很多人都把你加入好友名單，表示人氣越旺

```{r}
# 2 號員工是公司內最受歡迎的人，大概是公司裡的好好先生
deg_friendship_in <- degree(krack_friendship, mode="in") 
deg_friendship_in
```



配合一些簡單的統計
========================================================

```{r}
# 可以用 summary() 很快地看出資料的分佈狀況
summary(deg_friendship_in)

# mean() 計算平均值
mean(deg_friendship_in)

# sd() 計算標準差
sd(deg_friendship_in)
```



畫出 degree_in 的分佈 (1)
========================================================

```{r}
# 搭配使用 R 本身與 igraph 套件中的函式
degree.distribution(krack_friendship, mode="in")
```



畫出 degree_in 的分佈 (2)
========================================================

```{r}
plot(degree.distribution(krack_friendship, mode="in"), xlab="node degree")
lines(degree.distribution(krack_friendship, mode="in"))
```



來思考一下 out-degree 的意義
========================================================

套用前面的 krack_friendship 觀察看看，out-degree 越高，表示好友名單越長，認識的人越多

```{r}
# 17 號員工認識最多人，大概是人資主管一類的
deg_friendship_out <- degree(krack_friendship, mode="out") 
deg_friendship_out
```



配合一些簡單的統計
========================================================

```{r}
# 可以用 summary() 很快地看出資料的分佈狀況
summary(deg_friendship_out)

# mean() 計算平均值
mean(deg_friendship_out)

# sd() 計算標準差
sd(deg_friendship_out)
```



畫出 degree_out 的分佈 (1)
========================================================

```{r}
degree.distribution(krack_friendship, mode="out")
```



畫出 degree_out 的分佈 (2)
========================================================

```{r}
plot(degree.distribution(krack_friendship, mode="out"), xlab="node degree")

lines(degree.distribution(krack_friendship, mode="out"))
```



可達性 (Reachability)
========================================================

任意兩個端點間可以存在不同路徑，任意兩端點間若存在一路徑，則具有可達關係 (Reachable)
兩點若不相通，則無傳遞的路徑存在

跟 Degree 一樣，因連接線的方向分為兩種
- Reachability-In: 連入的可達性
- Reachability-Out: 連出的可達性



來思考一下 Reachability 的意義 (1)
========================================================

套用前面的 krack_friendship 觀察看看，確認端點與端點間的網路是否連通
以人際網路來說，就是誰認識誰，又可以透過誰去認識誰

```{r}
# 可使用 subcomponent()，確認端點與端點之間的連接性
reach_friendship_in <- subcomponent(krack_friendship, 17, mode="in")
reach_friendship_in
```



來思考一下 Reachability 的意義 (2)
========================================================

由 Reachability-Out 的結果來看，由 17 號員工所輻射出去的人際網路可以涵蓋公司的所有員工

```{r}
reach_friendship_out <- subcomponent(krack_friendship, 17, mode="out")
reach_friendship_out
```



最短路徑 (Shortest Paths) 
========================================================

通常我們想了解網絡中端點之間的路徑距離，除了透過可達性 (Reachability)，確認端點與端點間是否有相連的關係外．可以進一步透過最短路徑 (Shortest Paths) 了解 端點與端點間相連的關係

備註: 最短路徑 (Shortest Paths) 又稱測地線距離 (Geodesic Distance) 或簡稱距離 (Distance)，一樣都是指兩端點之間最短路徑的長度



來思考一下 Shortest Paths 的意義 (1)
========================================================

套用前面的 krack_friendship 觀察看看，簡單來說 Shortest Paths 就是計算誰與誰差了幾層朋友的關係

```{r}
# Compute shortest paths between each pair of nodes.
sp_friendship_in <- shortest.paths(krack_friendship, mode='in')
sp_friendship_in
```



來思考一下 shortest paths 的意義 (2)
========================================================

套用前面的 krack_friendship 觀察看看，簡單來說 Shortest Paths 就是計算誰與誰差了幾層朋友的關係

```{r}
sp_friendship_out <- shortest.paths(krack_friendship, mode='out')
sp_friendship_out
```



配合一些簡單的統計
========================================================

```{r}
mean(sp_friendship_in[which(sp_friendship_in != Inf)])
sd(sp_friendship_in[which(sp_friendship_in != Inf)])

mean(sp_friendship_out[which(sp_friendship_out != Inf)])
sd(sp_friendship_out[which(sp_friendship_out != Inf)])
```



計算端點與端點間的最短路徑
========================================================

```{r}
# shortest paths 1 to 13
sp <- get.all.shortest.paths(krack_friendship, 1, 13)
sp
```



在網路上畫出可能的最短路徑 (1)
========================================================

```{r}
# 設定一下 layout
E(krack_friendship)$color <- "grey"
for (p in sp$res) {E(krack_friendship, path=p)$color <- "red" }
```

```{r}
plot(krack_friendship, layout=layout.fruchterman.reingold)
```



在網路上畫出可能的最短路徑 (2)
========================================================

```{r}
# 有點亂，換個 layout 試試
plot(krack_friendship, 
     layout=layout.reingold.tilford)
```



中心性 (Centrality)
========================================================

中心性可分為三種，每一種所包含的意義皆不相同

- Closeness Centrality
- Betweenness Centrality
- Eigevector Centrality



Closeness Centrality
========================================================

Closeness Centrality gives a higher score to a node that has short path distance to every other nodes

Closeness Centrality 可找出人際網中最有效的訊息傳遞者 (因為該端點至該網路的其他端點最短路徑總和最小)

```{r}
closeness(krack_friendship)
```



Betweenness Centrality
========================================================

Betweenness Centrality 從網路中所有"成對"端點 (node pairs) 的最小路徑，找出座落於這些最短路徑上的點，並給予最高的分數

Betweenness Centrality 主要能夠識別人際網路溝通傳遞的樞紐點，區別多個不同且未曾有關聯的社群



用個範例說明一下
========================================================

下圖的 "4" 點 Betweenness Centrality 分數最高，為網路中的樞紐點，區分兩個不同的社群

```{r, echo=FALSE}
setwd('~/hackntu2016/sna/lab_2/')
bowtie <- read.table('bowtie_network.txt')
bowtie_sample <- graph.data.frame(bowtie)
plot(bowtie_sample, layout=layout.fruchterman.reingold)
```

```{r}
betweenness(bowtie_sample)
```



套用至 friendship 看看
========================================================

```{r}
betweenness(krack_friendship)
```



Eigevector Centrality
========================================================

Eigenvector Centrality 可找出網路中連結"多個重要端點"的端點

Eigenvector Centrality 可找出幕後的藏鏡人 (最近最有名的例子大概就是崔順實吧，人際關係網路連結並不如朴槿惠，但在幕後卻有相當的影響力 :P)

```{r}
evcent(krack_friendship)$vector
```



總結一下 (1)
========================================================

先前我們提到重要的點包含四種，我們可以用下面不同的方式找出
- 人際網路的明星 (Degree)
- 人際網路最有效的訊息傳遞者 (Closeness Centrality)
- 人際網路中不同群體的樞紐 (Betweenness Centrality)
- 人際網路中幕後決策的藏鏡人 (Eigenvector Centrality)



總結一下 (2)
========================================================

friendship 這個資料集真的不太適合拿來示範，怎麼都是同一個人 (17號員工)

希望各位有空可以回去試試其他的資料集

```{r}
order(deg_friendship_out, decreasing=TRUE)

order(closeness(krack_friendship), decreasing=TRUE)

order(betweenness(krack_friendship), decreasing=TRUE)

order(evcent(krack_friendship)$vector, decreasing=TRUE)
```



補充: Betweenness Centrality 與 Eigenvector Centrality
========================================================

從 Drew Conway 的研究中發現網路中低 Eigenvector Centrality 與高 Betweenness Centrality的端點是重要的守門人 (Gate Keepers)，如 21 號員工．

而高 Eigenvector Centrality 與低 Betweenness Centrality 的端點有直接接觸重要人物，如 19 號員工．

以上兩者在本資料集亦不顯著，原因為本資料網路密度相當高



補充: Betweenness Centrality 與 Eigenvector Centrality
========================================================

有興趣的人可以將 Eigenvector Centrality 與 Betweenness Centrality 畫出來看看

```{r}
plot(evcent(krack_friendship)$vector, betweenness(krack_friendship))
text(evcent(krack_friendship)$vector, betweenness(krack_friendship), 0:100, cex=0.6, pos=4)
```



補充: 最小生成樹 (Minimum Spanning Tree)
========================================================

最小生成樹演算法的目的是尋找 graph 中重要的連接端點，並以最小的權重總和連結整個 graph (故有多種可能性)

```{r}
# 備註: 一般在計算最小生成樹 (Minimum Spanning Tree) 時會考慮整體 graph 中 edges 的最小權重總和，但本資料集並無 edges 的權重資料，故只考慮關係是否存在 (0或1)

# 設定每個 edges 的權重
E(krack_friendship)$weight <- 1

plot(krack_friendship, 
     layout=layout.fruchterman.reingold, 
     edge.label=E(krack_friendship)$weight)
```



minimum.spanning.tree() 計算最小生成樹
========================================================

```{r}
# Compute the minimum spanning tree
mst <- minimum.spanning.tree(krack_friendship)
mst
```



觀察一下結果
========================================================

```{r}
plot(mst, 
     layout=layout.reingold.tilford, 
     edge.label=E(mst)$weight)
```



Question
========================================================

- What do these statistics tell us about each network and its individuals in general? 
- in-degree 或 out-degree 最高的人 (端點)，都在群體中扮演樞紐的角色，各位練習完可以思考對於這兩種人的行銷方針
- 對稱性



Network-Level Statistics
========================================================









強弱連結 (Strong/Weak Connection) 
========================================================

有向圖的網路連接包含兩種，強連結與弱連結
- 強連結: 端點間必須雙向都有路可通

![image](strong_connected.png)



強弱連結 (Strong/Weak Connection) 
========================================================

- 弱連結: 端點間至少單向有路可通

![image](weak_connected.png)


集群 (Clustering) (1)
========================================================

透過強弱連結可將網路中所有端點做集群

```{r}
# 由於本資料中存在太多弱連結，故無法有效集群
clusters(krack_friendship, mode="weak")
```



集群 (Clustering) (2)
========================================================

```{r}
# 使用強連結進行集群，可大致將網路中的端點分為三群
clusters(krack_friendship, mode="strong")
```



密度 (Density)
========================================================

圖密度指的是實際上觀察到的 edges 的數目，除以最大可能 edges 數目的比值，若 graph 中每一個端點與其他所有端點皆相連，則此圖稱為完全圖 (complete graph)，其密度為 1

Graph Density = (Connected Edges / All Possible Edges in Graph)

以社群網站的經營來講，密度可視為衡量整體用戶互動/參與度的指標

```{r}
graph.density(krack_friendship)
```



雙向性 (Reciprocity)
========================================================

雙向性的計算也很簡單，只不過計算的分子改為網路中雙向的 edges 的數目，分母改為網路中雙向與單向 edges 的數目

Reciprocity = (Two-Way Connected Edges / All Connected Edges in Graph)

也可視為衡量網路中整體用戶互動/參與度的指標

```{r}
reciprocity(krack_friendship)
```








傳遞性 (Transitivity)
========================================================

傳遞性Transitivity: 實際上具傳遞性的三人組比上所有可能的具有傳遞性的三人組

```{r}
transitivity(krack_friendship, type="global")
```



========================================================

```{r}
# Triad census. Here we'll first build a vector of labels for 
# the different triad types. Then we'll combine this vector
# with the triad censuses for the different networks, which 
# we'll .

census_labels = c('003',
                  '012',
                  '102',
                  '021D',
                  '021U',
                  '021C',
                  '111D',
                  '111U',
                  '030T',
                  '030C',
                  '201',
                  '120D',
                  '120U',
                  '120C',
                  '210',
                  '300')

tc_full <- triad.census(krack_full)
tc_advice <- triad.census(krack_advice)
tc_friendship <- triad.census(krack_friendship)
tc_reports_to <- triad.census(krack_reports_to)

triad_df <- data.frame(census_labels,
                       tc_full, 
                       tc_advice, 
                       tc_friendship,
                       tc_reports_to)
```


========================================================

```{r}
triad_df
```



========================================================
export as a CSV
```{r}
# To export any of these vectors to a CSV for use in another program, simply
# use the write.csv() command:
write.csv(triad_df, 'krack_triads.csv')
```



Question
========================================================

- How do the three networks differ on network statictics? 
- What does the triad census tell us? Can you calculate the likelihood of any triad's occurrence? 
- See the back of Wasserman and Faust and its section on triads. Calculate the degree of clustering and hierarchy in Excel. 
- What do we learn from that?




異質性 (Heterogeneity)
========================================================

異質性Heterogeneity: 人口在名目參數上的分佈情形
- 兩個隨機選取的人分屬於不同團體的機率
- 社會的團體愈多，每一個團體的人數愈平均，社會的異質程度越高
- 可以Blau index或entropy index 來衡量



========================================================

In particular, we look at the extent to which each actor's "associates" (friend, advisor, boss) are heterogenous or not.

特別是，我們看看每個參與者的"同事"（朋友，顧問，噓）是不同的或不同的程度。


We'll use a statistic called the IQV, or Index of Qualitative Variation. 
This is just an implementation of Blau's Index of Heterogeneity (known to economists as the Herfindahl-Hirschman index), normalized so that perfect heterogeneity (i.e., equal distribution across categories) equals 1.

我們將使用一個稱為IQV或定性變化索引的統計量。 這只是Blau的異質性指數（經濟學家稱為Herfindahl-Hirschman指數）的實現，其被歸一化以使得完美的異質性（即，類別之間的均勻分佈）等於1。



========================================================
We are interested in many of the attributes of nodes. To save time and to make our lives better we are going to create a function that will provide an IQV statistic for any network and for any categorical variable.  A function is a simple way to create code that is both reusable and easier to edit.

我們對節點的許多屬性感興趣。 為了節省時間並使我們的生活更好，我們將創建一個函數，為任何網絡和任何分類變量提供IQV統計。 函數是一種創建可重用和更易於編輯的代碼的簡單方法。



========================================================

```{r}
get_iqvs <- function(graph, attribute) {

# we have now defined a function, get_iqvs, that will take the graph "graph" and find the iqv statistic for the categorical variable "attribute." Within this function whenever we use the variables graph or attribute they correspond to the graph and variable we passed (provided) to the function

# 我們現在定義了一個函數 get_iqvs，它將獲取圖形 "graph"，並為分類變量 "attribute" 找到 iqv 統計量．在這個函數中，每當我們使用變量圖或屬性，它們對應於我們傳遞（提供）到函數的圖和變量

mat <- get.adjacency(graph)
				
# To make this function work on a wide variety of variables we
# find out how many coded levels (unique responses) exist for
# the attribute variable programatically

	attr_levels = get.vertex.attribute(graph,
	                                   attribute,
	                                   V(graph))
	
	num_levels = length(unique(attr_levels))
	iqvs = rep(0, nrow(mat))

# Now that we know how many levels exist we want to loop
# (go through) each actor in the network. Loops iterate through
# each value in a range.  Here we are looking through each ego
# in the range of egos starting at the first and ending at the
# last.  The function nrow provides the number of rows in an
# object and the ":" opperand specifies the range.  Between
# the curly braces of the for loop ego will represent exactly
# one value between 1 and the number of rows in the graph
# object, iterating by one during each execution of the loop.

	for (ego in 1:nrow(mat)) {
		
		# initialize actor-specific variables
		alter_attr_counts = rep(0, num_levels)
		num_alters_this_ego = 0
		sq_fraction_sum = 0

# For each ego we want to check each tied alter for the same
# level on the variable attribute as the ego.
	
		for (alter in 1:ncol(mat)) {
			
			# only examine alters that are actually tied to ego
			if (mat[ego, alter] == 1) {
				
				num_alters_this_ego = num_alters_this_ego + 1

				# get the alter's level on the attribute 
				alter_attr = get.vertex.attribute(graph, 
				    attribute, (alter - 1))

				# increment the count of alters with this level
				# of the attribute by 1
				alter_attr_counts[alter_attr + 1] =
				    alter_attr_counts[alter_attr + 1] + 1
			}
		}

		# now that we're done looping through all of the alters,
		# get the squared fraction for each level of the attribute
		# out of the total number of attributes
		for (i in 1:num_levels) {
			attr_fraction = alter_attr_counts[i] /
			    num_alters_this_ego
			sq_fraction_sum = sq_fraction_sum + attr_fraction ^ 2
		}
		
		# now we can compute the ego's blau index...
		blau_index = 1 - sq_fraction_sum
		
		# and the ego's IQV, which is just a normalized blau index
		iqvs[ego] = blau_index / (1 - (1 / num_levels))
	}

# The final part of a function returns the calculated value.
#  So if we called get_iqvs(testgraph, gender) return would
# provide the iqvs for gender in the test graph.  If we are also
# intersted in race we could simply change the function call
# to get_iqvs(testgraph, race).  No need to write all this
# code again for different variables.

	return(iqvs)
}

```




========================================================
```{r}
# For this data set, we'll look at homophily across departments, 
# which is already coded 0-4, so no recoding is needed. 

advice_iqvs <- get_iqvs(krack_advice, 'DEPT')
advice_iqvs
```


========================================================
```{r}
friendship_iqvs <- get_iqvs(krack_friendship, 'DEPT')
friendship_iqvs
```


========================================================
```{r}
reports_to_iqvs <- get_iqvs(krack_reports_to, 'DEPT')
reports_to_iqvs
```



Question
========================================================

What does the herfindahl index reveal about attribute sorting in networks? What does it mean for each network?
Extra-credit: What might be a better way to test the occurrence of homophily or segregation in a network? How might we code that in R?




